{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4b69a4-cc13-466e-819f-b88b9ba92b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "import json\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.callbacks import BaseCallbackManager, StdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dcafb9f-b0af-4428-bb1a-79c4c2949091",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-35\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad75906b-43e8-4e68-a3df-0be56e78f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_docker(**args):\n",
    "    \"Start Docker container\"\n",
    "    return \"STARTING Docker ...\"\n",
    "\n",
    "def stop_docker(container_id=\"###\"):\n",
    "    \"Stop Docker container\"\n",
    "    return f\"STOPPING Docker {container_id}\"\n",
    "\n",
    "def fetch_code():\n",
    "    \"Return code retriever results\"\n",
    "    return \"CODE Snippet ###\"\n",
    "\n",
    "def exec_shell():\n",
    "    \"Run shell command in shell\"\n",
    "    return \"SHELL Command ...\"\n",
    "\n",
    "\n",
    "tools = [start_docker, stop_docker, fetch_code, exec_shell]\n",
    "functions = [convert_to_openai_tool(t) for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aec071d9-1fbb-424d-9e1c-dd657eebebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'start_docker',\n",
       "   'description': 'Start Docker container',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'stop_docker',\n",
       "   'description': 'Stop Docker container',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'fetch_code',\n",
       "   'description': 'Return code retriever results',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'exec_shell',\n",
       "   'description': 'Run shell command in shell',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b7f1394-3445-4a61-9226-3190f9978033",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.bind_tools(functions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1125fb-3371-4604-a552-27f98312f69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! How can I help you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': 'fp_811936bd4f', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-54068428-2a27-4d69-a961-b795a14d9b3d-0', usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Say Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d9e3e4e1-5238-421d-82a9-6dde5ae9fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "029f939d-685a-47cc-8b0d-fd6c6bcb3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state['messages'][-1]\n",
    "    \n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cfd840f-6300-429f-83be-3a9545d5a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_prompt(state):\n",
    "    messages = state['messages']\n",
    "    sys_msg = SystemMessage(\"You are a helpful assistant, looking to for the best decision based on the available functions\")\n",
    "    return {\"messages\": [sys_msg]}\n",
    "\n",
    "def llm_response(state):\n",
    "    messages = state['messages']\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def exec_function(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] # this has the query we need to send to the tool provided by the agent\n",
    "\n",
    "    parsed_tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "    \n",
    "    print(\"parsed_tool_input:\")\n",
    "    print(\"--\"*50)\n",
    "    print(parsed_tool_input)\n",
    "    print(\"--\"*50)\n",
    "\n",
    "    # We construct an ToolInvocation from the function_call and pass in the tool name and the expected str input for OpenWeatherMap tool\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=parsed_tool_input['__arg1'],\n",
    "    )\n",
    "    \n",
    "    # # We call the tool_executor and get back a response\n",
    "    # response = tool_executor.invoke(action)\n",
    "\n",
    "    # # We use the response to create a FunctionMessage\n",
    "    # function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    tool_message = ToolMessage(content=\"None\", name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [tool_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a200eee-f334-46bf-8c7a-773e7fdd6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"start\", system_prompt)\n",
    "workflow.add_node(\"llm\", llm_response)\n",
    "workflow.add_node(\"tools\", exec_function)\n",
    "\n",
    "# workflow.add_edge('start', 'llm')\n",
    "# workflow.add_edge('llm', END)\n",
    "\n",
    "workflow.add_edge('start', 'llm')\n",
    "workflow.add_conditional_edges(\"llm\", should_continue, {\"continue\": \"tools\", \"end\": END})\n",
    "workflow.add_edge('tools', 'llm')\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"start\")\n",
    "app = workflow.compile()\n",
    "app.name=\"isseAgent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbd4351a-c2ad-452c-951b-26a1f3250011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.invoke(HumanMessage(\"get me a code snippet then test it in an isolated environment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34137564-a52b-4df4-97ac-36898ea19fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'start':\n",
      "---\n",
      "content='You are a helpful assistant, looking to for the best decision based on the available functions'\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'llm':\n",
      "---\n",
      "content='Here\\'s a simple Python code snippet that calculates the factorial of a given number:\\n\\n```python\\ndef factorial(n):\\n    if n == 0:\\n        return 1\\n    else:\\n        return n * factorial(n-1)\\n\\n# Test the factorial function\\nnumber = 5\\nresult = factorial(number)\\nprint(f\"The factorial of {number} is {result}\")\\n```\\n\\nTo test this code in an isolated environment, you can use an online Python compiler or an integrated development environment (IDE) such as PyCharm or Visual Studio Code. Simply copy and paste the code snippet into the environment and run it. You should see the output \"The factorial of 5 is 120\" printed to the console.' response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 40, 'total_tokens': 185}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': 'fp_811936bd4f', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-abe72e83-cc88-4a2c-9b41-ed1a6b11ba71-0' usage_metadata={'input_tokens': 40, 'output_tokens': 145, 'total_tokens': 185}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [HumanMessage(\"get me a code snippet then test it in an isolated environment\")]}\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value[\"messages\"][0])\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0d6b4-572e-457b-9808-46ebe4bacb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.aget_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbbdd2-a745-4cad-982e-91890eb1012d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adf44d-fbb1-472f-b4ff-b85426663526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e4dda-07b7-47ea-beee-9e42882dee9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
