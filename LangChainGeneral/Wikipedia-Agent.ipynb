{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load openai api key\n",
    "load_dotenv(Path().cwd().parent / '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# load openai llm model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "\n",
    "\n",
    "tools = load_tools(['wikipedia'], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(text):\n",
    "    pprint(agent.run(input=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Wikipedia to find the definition and explanation of negative predictive values in a confusion matrix.\n",
      "Action: Wikipedia\n",
      "Action Input: \"negative predictive values in a confusion matrix\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Confusion matrix\n",
      "Summary: In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one; in unsupervised learning it is usually called a matching matrix. \n",
      "Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class, or vice versa – both variants are found in the literature. The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another).\n",
      "It is a special kind of contingency table, with two dimensions (\"actual\" and \"predicted\"), and identical sets of \"classes\" in both dimensions (each combination of dimension and class is a variable in the contingency table).\n",
      "\n",
      "Page: Positive and negative predictive values\n",
      "Summary: The positive and negative predictive values (PPV and NPV respectively) are the proportions of positive and negative results in statistics and diagnostic tests that are true positive and true negative results, respectively.  The PPV and NPV describe the performance of a diagnostic test or other statistical measure. A high result can be interpreted as indicating the accuracy of such a statistic. The PPV and NPV are not intrinsic to the test (as true positive rate and true negative rate are); they depend also on the prevalence. Both PPV and NPV can be derived using Bayes' theorem.\n",
      "Although sometimes used synonymously, a positive predictive value generally refers to what is established by control groups, while a post-test probability refers to a probability for an individual. Still, if the individual's pre-test probability of the target condition is the same as the prevalence in the control group used to establish the positive predictive value, the two are numerically equal.\n",
      "In information retrieval, the PPV statistic is often called the precision.\n",
      "\n",
      "Page: Phi coefficient\n",
      "Summary: In statistics, the phi coefficient (or mean square contingency coefficient and denoted by φ or rφ) is a measure of association for two binary variables.\n",
      "In machine learning, it is known as the Matthews correlation coefficient (MCC) and used as a measure of the quality of binary (two-class) classifications, introduced by biochemist Brian W. Matthews in 1975.Introduced by Karl Pearson, and also known as the Yule phi coefficient from its introduction by Udny Yule in 1912 this measure is similar to the Pearson correlation coefficient in its interpretation.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Negative predictive values in a confusion matrix refer to the proportion of true negative results in statistics and diagnostic tests. It is a measure of the accuracy of a diagnostic test or statistical measure.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('Negative predictive values in a confusion matrix refer to the proportion of '\n",
      " 'true negative results in statistics and diagnostic tests. It is a measure of '\n",
      " 'the accuracy of a diagnostic test or statistical measure.')\n"
     ]
    }
   ],
   "source": [
    "run('Explain what is negative predictive values in a confusion matrix?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for information on recall and precision and how they are related.\n",
      "Action: Wikipedia\n",
      "Action Input: \"recall and precision\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Precision and recall\n",
      "Summary: In pattern recognition, information retrieval, object detection and classification (machine learning), precision and recall are performance metrics that apply to data retrieved from a collection, corpus or sample space.\n",
      "Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances. Written as a formula:\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              r\n",
      "              e\n",
      "              l\n",
      "              e\n",
      "              v\n",
      "              a\n",
      "              n\n",
      "              t\n",
      "              _\n",
      "              r\n",
      "              e\n",
      "              t\n",
      "              r\n",
      "              i\n",
      "              e\n",
      "              v\n",
      "              e\n",
      "              d\n",
      "              _\n",
      "              i\n",
      "              n\n",
      "              s\n",
      "              t\n",
      "              a\n",
      "              n\n",
      "              c\n",
      "              e\n",
      "              s\n",
      "            \n",
      "            \n",
      "              a\n",
      "              l\n",
      "              l\n",
      "              _\n",
      "              \n",
      "                \n",
      "                  r\n",
      "                  e\n",
      "                  t\n",
      "                  r\n",
      "                  i\n",
      "                  e\n",
      "                  v\n",
      "                  e\n",
      "                  d\n",
      "                \n",
      "              \n",
      "              _\n",
      "              i\n",
      "              n\n",
      "              s\n",
      "              t\n",
      "              a\n",
      "              n\n",
      "              c\n",
      "              e\n",
      "              s\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\frac {relevant\\_retrieved\\_instances}{all\\_{\\mathbf {retrieved}}\\_instances}}}\n",
      "  . \n",
      "Recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Written as a formula: \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              r\n",
      "              e\n",
      "              l\n",
      "              e\n",
      "              v\n",
      "              a\n",
      "              n\n",
      "              t\n",
      "              _\n",
      "              r\n",
      "              e\n",
      "              t\n",
      "              r\n",
      "              i\n",
      "              e\n",
      "              v\n",
      "              e\n",
      "              d\n",
      "              _\n",
      "              i\n",
      "              n\n",
      "              s\n",
      "              t\n",
      "              a\n",
      "              n\n",
      "              c\n",
      "              e\n",
      "              s\n",
      "            \n",
      "            \n",
      "              a\n",
      "              l\n",
      "              l\n",
      "              _\n",
      "              \n",
      "                \n",
      "                  r\n",
      "                  e\n",
      "                  l\n",
      "                  e\n",
      "                  v\n",
      "                  a\n",
      "                  n\n",
      "                  t\n",
      "                \n",
      "              \n",
      "              _\n",
      "              i\n",
      "              n\n",
      "              s\n",
      "              t\n",
      "              a\n",
      "              n\n",
      "              c\n",
      "              e\n",
      "              s\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\frac {relevant\\_retrieved\\_instances}{all\\_{\\mathbf {relevant}}\\_instances}}}\n",
      "  . Both precision and recall are therefore based on relevance. \n",
      "Consider a computer program for recognizing dogs (the relevant element) in a digital photograph. Upon processing a picture which contains ten cats and twelve dogs, the program identifies eight dogs. Of the eight elements identified as dogs, only five actually are dogs (true positives), while the other three are cats (false positives). Seven dogs were missed (false negatives), and seven cats were correctly excluded (true negatives). The program's precision is then 5/8 (true positives / selected elements) while its recall is 5/12 (true positives / relevant elements).\n",
      "Adopting a hypothesis-testing approach from statistics, in which, in this case, the null hypothesis is that a given item is irrelevant (i.e., not a dog), absence of type I and type II errors (i.e., perfect specificity and sensitivity of 100% each) corresponds respectively to perfect precision (no false positive) and perfect recall (no false negative).  \n",
      "More generally, recall is simply the complement of the type II error rate (i.e., one minus the type II error rate). Precision is related to the type I error rate, but in a slightly more complicated way, as it also depends upon the prior di\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now understand the relationship between recall and precision. Recall is the fraction of relevant instances that were retrieved, while precision is the fraction of retrieved instances that are relevant. They are both performance metrics that apply to data retrieved from a collection or sample space. \n",
      "\n",
      "Final Answer: Recall and precision are related metrics used in pattern recognition, information retrieval, and machine learning to evaluate the performance of data retrieval.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('Recall and precision are related metrics used in pattern recognition, '\n",
      " 'information retrieval, and machine learning to evaluate the performance of '\n",
      " 'data retrieval.')\n"
     ]
    }
   ],
   "source": [
    "run('What is the relationship between recall and precision?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
